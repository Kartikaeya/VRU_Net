{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride, padding, bn = True, relu = True):\n",
    "        super(Conv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_dim, out_dim, kernel , stride = stride, padding = padding)\n",
    "        if bn:\n",
    "            self.is_bn = True\n",
    "            self.batchnorm = nn.BatchNorm2d(out_dim)\n",
    "        if relu:\n",
    "            self.is_relu = True\n",
    "            self.relu = nn.ReLU()\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if self.is_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.is_relu:\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride, in_padding, out_padding = 0, bn = True, relu = True):\n",
    "        super(DeConv, self).__init__()\n",
    "        self.convTranspose = nn.ConvTranspose2d(in_dim, out_dim, kernel , stride = stride, padding = in_padding, output_padding = out_padding)\n",
    "        if bn:\n",
    "            self.is_bn = True\n",
    "            self.batchnorm = nn.BatchNorm2d(out_dim)\n",
    "        if relu:\n",
    "            self.is_relu = True\n",
    "            self.relu = nn.ReLU()\n",
    "    def forward(self , x):\n",
    "        x = self.convTranspose(x)\n",
    "        if self.is_bn:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.is_relu:\n",
    "            x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackBone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BackBone, self).__init__()\n",
    "        \n",
    "        self.bb1 = nn.Sequential(\n",
    "            Conv(3, 16, 7, 1, 3),\n",
    "            Conv(16, 16, 7, 1, 3),\n",
    "            Conv(16, 32, 3, 1, 1),\n",
    "            Conv(32, 64, 3, 2, 1)\n",
    "        )\n",
    "        self.bb2 = nn.Sequential(\n",
    "            Conv(128, 128, 7, 1, 3),\n",
    "            Conv(128, 128, 7, 1, 3),\n",
    "            Conv(128, 128, 3, 1, 1),\n",
    "            Conv(128, 128, 3, 2, 1)\n",
    "        )\n",
    "        \n",
    "        self.bb3 = nn.Sequential(\n",
    "            Conv(256, 256, 5, 1, 2),\n",
    "            Conv(256, 256, 5, 1, 2),\n",
    "            Conv(256, 256, 3, 1, 1),\n",
    "            Conv(256, 256, 3, 1, 1)\n",
    "        )\n",
    "        self.skip1 = nn.Conv2d(3, 64, 3, stride = 2, padding = 1)\n",
    "        self.skip2 = nn.Sequential(\n",
    "            Conv(3, 64, 3, stride = 2, padding = 1),\n",
    "            Conv(64, 128, 3, stride = 2, padding = 1)\n",
    "        )\n",
    "        \n",
    "        self.upsample1 = nn.Sequential(\n",
    "            DeConv(256, 128, 3, 2, 1, 1),\n",
    "            Conv(128,128, 3, 1, 1),\n",
    "            DeConv(128, 64, 3, 2, 1, 1),\n",
    "            Conv(64,32, 3, 1, 1),\n",
    "            Conv(32,17, 3, 1, 1)\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_shape = x.shape\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        temp = x\n",
    "        \n",
    "        out = self.bb1(x)\n",
    "        residual1 = self.skip1(temp)\n",
    "        out = torch.cat((out, residual1), 1)\n",
    "        \n",
    "        out = self.bb2(out)\n",
    "        residual2 = self.skip2(temp)\n",
    "        out = torch.cat((out, residual2), 1)\n",
    "        \n",
    "        out = self.bb3(out)\n",
    "        out = self.upsample1(out)\n",
    "        \n",
    "        out = F.interpolate(out, (input_shape[2], input_shape[3]), mode = 'bilinear')\n",
    "    \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Downsample, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            Conv(in_channels, in_channels, 3, 1, 1),\n",
    "            Conv(in_channels, in_channels, 3, 1, 1),\n",
    "            Conv(in_channels, in_channels*2, 3, 2, 2),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.conv = nn.Sequential(    \n",
    "            Conv(in_channels, in_channels//2, 3, 1, 1),\n",
    "            Conv(in_channels//2, in_channels//2, 3, 1, 1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "#         self.img = img\n",
    "        self.conv1 = Conv(20, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.ModuleList([Downsample(32*(2**(i-1))) for i in range(1, 5)])\n",
    "        self.conv3 = nn.ModuleList([DeConv(32*(2**(5-i)),32*(2**(5-i))//2, 2, 2, 1) for i in range(1, 5)])\n",
    "        self.conv4 = nn.ModuleList([Upsample(32*(2**(5-i))) for i in range(1, 5)])\n",
    "        self.conv5 = Conv(32, 17, 3, 1, 1)\n",
    "    def forward(self, x):\n",
    "#         x = torch.cat((x, self.img), 1)\n",
    "        x = nn.MaxPool2d(2, 2)(x)\n",
    "        x = self.conv1(x)\n",
    "        skip_connections = []\n",
    "        skip_connections.append(x)\n",
    "        for i in range(4):\n",
    "            x = self.conv2[i](x)\n",
    "            skip_connections.append(x)\n",
    "        for i in range(4):\n",
    "            x = self.conv3[i](x)\n",
    "            target_shape = x.shape\n",
    "            interpolated_layer = F.interpolate(skip_connections[3-i], (target_shape[2], target_shape[3]), mode = 'bilinear')\n",
    "            x = torch.cat((x, interpolated_layer), 1)\n",
    "#             print(x.shape)\n",
    "            x = self.conv4[i](x)\n",
    "        x = self.conv5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VRUNet, self).__init__()\n",
    "        self.Backbone = BackBone()\n",
    "        self.Unet_module = nn.ModuleList([Unet() for i in range(3)])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        input_img = x\n",
    "        confidence_maps_tensor = torch.zeros(x.shape[0], 17*4, x.shape[2], x.shape[3], device = device)\n",
    "        confidence_maps = []\n",
    "        x = self.Backbone(x)\n",
    "        \n",
    "        confidence_maps.append(x)\n",
    "        \n",
    "        for i in range(3):\n",
    "            x = torch.cat((x, input_img), 1)\n",
    "            x = self.Unet_module[i](x)\n",
    "            x = F.interpolate(x, (input_img.shape[2], input_img.shape[3]), mode = 'bilinear')\n",
    "            confidence_maps.append(x)\n",
    "            \n",
    "        for i in range(input_img.shape[0]):\n",
    "            for j in range(4):\n",
    "                confidence_maps_tensor[i, 17*j:(17*j + 17), :, :] = confidence_maps[j][i]\n",
    "        return confidence_maps_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kartikaeya\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 134, 58]           2,368\n",
      "       BatchNorm2d-2          [-1, 16, 134, 58]              32\n",
      "              ReLU-3          [-1, 16, 134, 58]               0\n",
      "              Conv-4          [-1, 16, 134, 58]               0\n",
      "            Conv2d-5          [-1, 16, 134, 58]          12,560\n",
      "       BatchNorm2d-6          [-1, 16, 134, 58]              32\n",
      "              ReLU-7          [-1, 16, 134, 58]               0\n",
      "              Conv-8          [-1, 16, 134, 58]               0\n",
      "            Conv2d-9          [-1, 32, 134, 58]           4,640\n",
      "      BatchNorm2d-10          [-1, 32, 134, 58]              64\n",
      "             ReLU-11          [-1, 32, 134, 58]               0\n",
      "             Conv-12          [-1, 32, 134, 58]               0\n",
      "           Conv2d-13           [-1, 64, 67, 29]          18,496\n",
      "      BatchNorm2d-14           [-1, 64, 67, 29]             128\n",
      "             ReLU-15           [-1, 64, 67, 29]               0\n",
      "             Conv-16           [-1, 64, 67, 29]               0\n",
      "           Conv2d-17           [-1, 64, 67, 29]           1,792\n",
      "           Conv2d-18          [-1, 128, 67, 29]         802,944\n",
      "      BatchNorm2d-19          [-1, 128, 67, 29]             256\n",
      "             ReLU-20          [-1, 128, 67, 29]               0\n",
      "             Conv-21          [-1, 128, 67, 29]               0\n",
      "           Conv2d-22          [-1, 128, 67, 29]         802,944\n",
      "      BatchNorm2d-23          [-1, 128, 67, 29]             256\n",
      "             ReLU-24          [-1, 128, 67, 29]               0\n",
      "             Conv-25          [-1, 128, 67, 29]               0\n",
      "           Conv2d-26          [-1, 128, 67, 29]         147,584\n",
      "      BatchNorm2d-27          [-1, 128, 67, 29]             256\n",
      "             ReLU-28          [-1, 128, 67, 29]               0\n",
      "             Conv-29          [-1, 128, 67, 29]               0\n",
      "           Conv2d-30          [-1, 128, 34, 15]         147,584\n",
      "      BatchNorm2d-31          [-1, 128, 34, 15]             256\n",
      "             ReLU-32          [-1, 128, 34, 15]               0\n",
      "             Conv-33          [-1, 128, 34, 15]               0\n",
      "           Conv2d-34           [-1, 64, 67, 29]           1,792\n",
      "      BatchNorm2d-35           [-1, 64, 67, 29]             128\n",
      "             ReLU-36           [-1, 64, 67, 29]               0\n",
      "             Conv-37           [-1, 64, 67, 29]               0\n",
      "           Conv2d-38          [-1, 128, 34, 15]          73,856\n",
      "      BatchNorm2d-39          [-1, 128, 34, 15]             256\n",
      "             ReLU-40          [-1, 128, 34, 15]               0\n",
      "             Conv-41          [-1, 128, 34, 15]               0\n",
      "           Conv2d-42          [-1, 256, 34, 15]       1,638,656\n",
      "      BatchNorm2d-43          [-1, 256, 34, 15]             512\n",
      "             ReLU-44          [-1, 256, 34, 15]               0\n",
      "             Conv-45          [-1, 256, 34, 15]               0\n",
      "           Conv2d-46          [-1, 256, 34, 15]       1,638,656\n",
      "      BatchNorm2d-47          [-1, 256, 34, 15]             512\n",
      "             ReLU-48          [-1, 256, 34, 15]               0\n",
      "             Conv-49          [-1, 256, 34, 15]               0\n",
      "           Conv2d-50          [-1, 256, 34, 15]         590,080\n",
      "      BatchNorm2d-51          [-1, 256, 34, 15]             512\n",
      "             ReLU-52          [-1, 256, 34, 15]               0\n",
      "             Conv-53          [-1, 256, 34, 15]               0\n",
      "           Conv2d-54          [-1, 256, 34, 15]         590,080\n",
      "      BatchNorm2d-55          [-1, 256, 34, 15]             512\n",
      "             ReLU-56          [-1, 256, 34, 15]               0\n",
      "             Conv-57          [-1, 256, 34, 15]               0\n",
      "  ConvTranspose2d-58          [-1, 128, 68, 30]         295,040\n",
      "      BatchNorm2d-59          [-1, 128, 68, 30]             256\n",
      "             ReLU-60          [-1, 128, 68, 30]               0\n",
      "           DeConv-61          [-1, 128, 68, 30]               0\n",
      "           Conv2d-62          [-1, 128, 68, 30]         147,584\n",
      "      BatchNorm2d-63          [-1, 128, 68, 30]             256\n",
      "             ReLU-64          [-1, 128, 68, 30]               0\n",
      "             Conv-65          [-1, 128, 68, 30]               0\n",
      "  ConvTranspose2d-66          [-1, 64, 136, 60]          73,792\n",
      "      BatchNorm2d-67          [-1, 64, 136, 60]             128\n",
      "             ReLU-68          [-1, 64, 136, 60]               0\n",
      "           DeConv-69          [-1, 64, 136, 60]               0\n",
      "           Conv2d-70          [-1, 32, 136, 60]          18,464\n",
      "      BatchNorm2d-71          [-1, 32, 136, 60]              64\n",
      "             ReLU-72          [-1, 32, 136, 60]               0\n",
      "             Conv-73          [-1, 32, 136, 60]               0\n",
      "           Conv2d-74          [-1, 17, 136, 60]           4,913\n",
      "      BatchNorm2d-75          [-1, 17, 136, 60]              34\n",
      "             ReLU-76          [-1, 17, 136, 60]               0\n",
      "             Conv-77          [-1, 17, 136, 60]               0\n",
      "         BackBone-78         [-1, 17, 269, 117]               0\n",
      "           Conv2d-79          [-1, 32, 134, 58]           5,792\n",
      "      BatchNorm2d-80          [-1, 32, 134, 58]              64\n",
      "             ReLU-81          [-1, 32, 134, 58]               0\n",
      "             Conv-82          [-1, 32, 134, 58]               0\n",
      "           Conv2d-83          [-1, 32, 134, 58]           9,248\n",
      "      BatchNorm2d-84          [-1, 32, 134, 58]              64\n",
      "             ReLU-85          [-1, 32, 134, 58]               0\n",
      "             Conv-86          [-1, 32, 134, 58]               0\n",
      "           Conv2d-87          [-1, 32, 134, 58]           9,248\n",
      "      BatchNorm2d-88          [-1, 32, 134, 58]              64\n",
      "             ReLU-89          [-1, 32, 134, 58]               0\n",
      "             Conv-90          [-1, 32, 134, 58]               0\n",
      "           Conv2d-91           [-1, 64, 68, 30]          18,496\n",
      "      BatchNorm2d-92           [-1, 64, 68, 30]             128\n",
      "             ReLU-93           [-1, 64, 68, 30]               0\n",
      "             Conv-94           [-1, 64, 68, 30]               0\n",
      "       Downsample-95           [-1, 64, 68, 30]               0\n",
      "           Conv2d-96           [-1, 64, 68, 30]          36,928\n",
      "      BatchNorm2d-97           [-1, 64, 68, 30]             128\n",
      "             ReLU-98           [-1, 64, 68, 30]               0\n",
      "             Conv-99           [-1, 64, 68, 30]               0\n",
      "          Conv2d-100           [-1, 64, 68, 30]          36,928\n",
      "     BatchNorm2d-101           [-1, 64, 68, 30]             128\n",
      "            ReLU-102           [-1, 64, 68, 30]               0\n",
      "            Conv-103           [-1, 64, 68, 30]               0\n",
      "          Conv2d-104          [-1, 128, 35, 16]          73,856\n",
      "     BatchNorm2d-105          [-1, 128, 35, 16]             256\n",
      "            ReLU-106          [-1, 128, 35, 16]               0\n",
      "            Conv-107          [-1, 128, 35, 16]               0\n",
      "      Downsample-108          [-1, 128, 35, 16]               0\n",
      "          Conv2d-109          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-110          [-1, 128, 35, 16]             256\n",
      "            ReLU-111          [-1, 128, 35, 16]               0\n",
      "            Conv-112          [-1, 128, 35, 16]               0\n",
      "          Conv2d-113          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-114          [-1, 128, 35, 16]             256\n",
      "            ReLU-115          [-1, 128, 35, 16]               0\n",
      "            Conv-116          [-1, 128, 35, 16]               0\n",
      "          Conv2d-117           [-1, 256, 19, 9]         295,168\n",
      "     BatchNorm2d-118           [-1, 256, 19, 9]             512\n",
      "            ReLU-119           [-1, 256, 19, 9]               0\n",
      "            Conv-120           [-1, 256, 19, 9]               0\n",
      "      Downsample-121           [-1, 256, 19, 9]               0\n",
      "          Conv2d-122           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-123           [-1, 256, 19, 9]             512\n",
      "            ReLU-124           [-1, 256, 19, 9]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Conv-125           [-1, 256, 19, 9]               0\n",
      "          Conv2d-126           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-127           [-1, 256, 19, 9]             512\n",
      "            ReLU-128           [-1, 256, 19, 9]               0\n",
      "            Conv-129           [-1, 256, 19, 9]               0\n",
      "          Conv2d-130           [-1, 512, 11, 6]       1,180,160\n",
      "     BatchNorm2d-131           [-1, 512, 11, 6]           1,024\n",
      "            ReLU-132           [-1, 512, 11, 6]               0\n",
      "            Conv-133           [-1, 512, 11, 6]               0\n",
      "      Downsample-134           [-1, 512, 11, 6]               0\n",
      " ConvTranspose2d-135          [-1, 256, 20, 10]         524,544\n",
      "     BatchNorm2d-136          [-1, 256, 20, 10]             512\n",
      "            ReLU-137          [-1, 256, 20, 10]               0\n",
      "          DeConv-138          [-1, 256, 20, 10]               0\n",
      "          Conv2d-139          [-1, 256, 20, 10]       1,179,904\n",
      "     BatchNorm2d-140          [-1, 256, 20, 10]             512\n",
      "            ReLU-141          [-1, 256, 20, 10]               0\n",
      "            Conv-142          [-1, 256, 20, 10]               0\n",
      "          Conv2d-143          [-1, 256, 20, 10]         590,080\n",
      "     BatchNorm2d-144          [-1, 256, 20, 10]             512\n",
      "            ReLU-145          [-1, 256, 20, 10]               0\n",
      "            Conv-146          [-1, 256, 20, 10]               0\n",
      "        Upsample-147          [-1, 256, 20, 10]               0\n",
      " ConvTranspose2d-148          [-1, 128, 38, 18]         131,200\n",
      "     BatchNorm2d-149          [-1, 128, 38, 18]             256\n",
      "            ReLU-150          [-1, 128, 38, 18]               0\n",
      "          DeConv-151          [-1, 128, 38, 18]               0\n",
      "          Conv2d-152          [-1, 128, 38, 18]         295,040\n",
      "     BatchNorm2d-153          [-1, 128, 38, 18]             256\n",
      "            ReLU-154          [-1, 128, 38, 18]               0\n",
      "            Conv-155          [-1, 128, 38, 18]               0\n",
      "          Conv2d-156          [-1, 128, 38, 18]         147,584\n",
      "     BatchNorm2d-157          [-1, 128, 38, 18]             256\n",
      "            ReLU-158          [-1, 128, 38, 18]               0\n",
      "            Conv-159          [-1, 128, 38, 18]               0\n",
      "        Upsample-160          [-1, 128, 38, 18]               0\n",
      " ConvTranspose2d-161           [-1, 64, 74, 34]          32,832\n",
      "     BatchNorm2d-162           [-1, 64, 74, 34]             128\n",
      "            ReLU-163           [-1, 64, 74, 34]               0\n",
      "          DeConv-164           [-1, 64, 74, 34]               0\n",
      "          Conv2d-165           [-1, 64, 74, 34]          73,792\n",
      "     BatchNorm2d-166           [-1, 64, 74, 34]             128\n",
      "            ReLU-167           [-1, 64, 74, 34]               0\n",
      "            Conv-168           [-1, 64, 74, 34]               0\n",
      "          Conv2d-169           [-1, 64, 74, 34]          36,928\n",
      "     BatchNorm2d-170           [-1, 64, 74, 34]             128\n",
      "            ReLU-171           [-1, 64, 74, 34]               0\n",
      "            Conv-172           [-1, 64, 74, 34]               0\n",
      "        Upsample-173           [-1, 64, 74, 34]               0\n",
      " ConvTranspose2d-174          [-1, 32, 146, 66]           8,224\n",
      "     BatchNorm2d-175          [-1, 32, 146, 66]              64\n",
      "            ReLU-176          [-1, 32, 146, 66]               0\n",
      "          DeConv-177          [-1, 32, 146, 66]               0\n",
      "          Conv2d-178          [-1, 32, 146, 66]          18,464\n",
      "     BatchNorm2d-179          [-1, 32, 146, 66]              64\n",
      "            ReLU-180          [-1, 32, 146, 66]               0\n",
      "            Conv-181          [-1, 32, 146, 66]               0\n",
      "          Conv2d-182          [-1, 32, 146, 66]           9,248\n",
      "     BatchNorm2d-183          [-1, 32, 146, 66]              64\n",
      "            ReLU-184          [-1, 32, 146, 66]               0\n",
      "            Conv-185          [-1, 32, 146, 66]               0\n",
      "        Upsample-186          [-1, 32, 146, 66]               0\n",
      "          Conv2d-187          [-1, 17, 146, 66]           4,913\n",
      "     BatchNorm2d-188          [-1, 17, 146, 66]              34\n",
      "            ReLU-189          [-1, 17, 146, 66]               0\n",
      "            Conv-190          [-1, 17, 146, 66]               0\n",
      "            Unet-191          [-1, 17, 146, 66]               0\n",
      "          Conv2d-192          [-1, 32, 134, 58]           5,792\n",
      "     BatchNorm2d-193          [-1, 32, 134, 58]              64\n",
      "            ReLU-194          [-1, 32, 134, 58]               0\n",
      "            Conv-195          [-1, 32, 134, 58]               0\n",
      "          Conv2d-196          [-1, 32, 134, 58]           9,248\n",
      "     BatchNorm2d-197          [-1, 32, 134, 58]              64\n",
      "            ReLU-198          [-1, 32, 134, 58]               0\n",
      "            Conv-199          [-1, 32, 134, 58]               0\n",
      "          Conv2d-200          [-1, 32, 134, 58]           9,248\n",
      "     BatchNorm2d-201          [-1, 32, 134, 58]              64\n",
      "            ReLU-202          [-1, 32, 134, 58]               0\n",
      "            Conv-203          [-1, 32, 134, 58]               0\n",
      "          Conv2d-204           [-1, 64, 68, 30]          18,496\n",
      "     BatchNorm2d-205           [-1, 64, 68, 30]             128\n",
      "            ReLU-206           [-1, 64, 68, 30]               0\n",
      "            Conv-207           [-1, 64, 68, 30]               0\n",
      "      Downsample-208           [-1, 64, 68, 30]               0\n",
      "          Conv2d-209           [-1, 64, 68, 30]          36,928\n",
      "     BatchNorm2d-210           [-1, 64, 68, 30]             128\n",
      "            ReLU-211           [-1, 64, 68, 30]               0\n",
      "            Conv-212           [-1, 64, 68, 30]               0\n",
      "          Conv2d-213           [-1, 64, 68, 30]          36,928\n",
      "     BatchNorm2d-214           [-1, 64, 68, 30]             128\n",
      "            ReLU-215           [-1, 64, 68, 30]               0\n",
      "            Conv-216           [-1, 64, 68, 30]               0\n",
      "          Conv2d-217          [-1, 128, 35, 16]          73,856\n",
      "     BatchNorm2d-218          [-1, 128, 35, 16]             256\n",
      "            ReLU-219          [-1, 128, 35, 16]               0\n",
      "            Conv-220          [-1, 128, 35, 16]               0\n",
      "      Downsample-221          [-1, 128, 35, 16]               0\n",
      "          Conv2d-222          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-223          [-1, 128, 35, 16]             256\n",
      "            ReLU-224          [-1, 128, 35, 16]               0\n",
      "            Conv-225          [-1, 128, 35, 16]               0\n",
      "          Conv2d-226          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-227          [-1, 128, 35, 16]             256\n",
      "            ReLU-228          [-1, 128, 35, 16]               0\n",
      "            Conv-229          [-1, 128, 35, 16]               0\n",
      "          Conv2d-230           [-1, 256, 19, 9]         295,168\n",
      "     BatchNorm2d-231           [-1, 256, 19, 9]             512\n",
      "            ReLU-232           [-1, 256, 19, 9]               0\n",
      "            Conv-233           [-1, 256, 19, 9]               0\n",
      "      Downsample-234           [-1, 256, 19, 9]               0\n",
      "          Conv2d-235           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-236           [-1, 256, 19, 9]             512\n",
      "            ReLU-237           [-1, 256, 19, 9]               0\n",
      "            Conv-238           [-1, 256, 19, 9]               0\n",
      "          Conv2d-239           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-240           [-1, 256, 19, 9]             512\n",
      "            ReLU-241           [-1, 256, 19, 9]               0\n",
      "            Conv-242           [-1, 256, 19, 9]               0\n",
      "          Conv2d-243           [-1, 512, 11, 6]       1,180,160\n",
      "     BatchNorm2d-244           [-1, 512, 11, 6]           1,024\n",
      "            ReLU-245           [-1, 512, 11, 6]               0\n",
      "            Conv-246           [-1, 512, 11, 6]               0\n",
      "      Downsample-247           [-1, 512, 11, 6]               0\n",
      " ConvTranspose2d-248          [-1, 256, 20, 10]         524,544\n",
      "     BatchNorm2d-249          [-1, 256, 20, 10]             512\n",
      "            ReLU-250          [-1, 256, 20, 10]               0\n",
      "          DeConv-251          [-1, 256, 20, 10]               0\n",
      "          Conv2d-252          [-1, 256, 20, 10]       1,179,904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-253          [-1, 256, 20, 10]             512\n",
      "            ReLU-254          [-1, 256, 20, 10]               0\n",
      "            Conv-255          [-1, 256, 20, 10]               0\n",
      "          Conv2d-256          [-1, 256, 20, 10]         590,080\n",
      "     BatchNorm2d-257          [-1, 256, 20, 10]             512\n",
      "            ReLU-258          [-1, 256, 20, 10]               0\n",
      "            Conv-259          [-1, 256, 20, 10]               0\n",
      "        Upsample-260          [-1, 256, 20, 10]               0\n",
      " ConvTranspose2d-261          [-1, 128, 38, 18]         131,200\n",
      "     BatchNorm2d-262          [-1, 128, 38, 18]             256\n",
      "            ReLU-263          [-1, 128, 38, 18]               0\n",
      "          DeConv-264          [-1, 128, 38, 18]               0\n",
      "          Conv2d-265          [-1, 128, 38, 18]         295,040\n",
      "     BatchNorm2d-266          [-1, 128, 38, 18]             256\n",
      "            ReLU-267          [-1, 128, 38, 18]               0\n",
      "            Conv-268          [-1, 128, 38, 18]               0\n",
      "          Conv2d-269          [-1, 128, 38, 18]         147,584\n",
      "     BatchNorm2d-270          [-1, 128, 38, 18]             256\n",
      "            ReLU-271          [-1, 128, 38, 18]               0\n",
      "            Conv-272          [-1, 128, 38, 18]               0\n",
      "        Upsample-273          [-1, 128, 38, 18]               0\n",
      " ConvTranspose2d-274           [-1, 64, 74, 34]          32,832\n",
      "     BatchNorm2d-275           [-1, 64, 74, 34]             128\n",
      "            ReLU-276           [-1, 64, 74, 34]               0\n",
      "          DeConv-277           [-1, 64, 74, 34]               0\n",
      "          Conv2d-278           [-1, 64, 74, 34]          73,792\n",
      "     BatchNorm2d-279           [-1, 64, 74, 34]             128\n",
      "            ReLU-280           [-1, 64, 74, 34]               0\n",
      "            Conv-281           [-1, 64, 74, 34]               0\n",
      "          Conv2d-282           [-1, 64, 74, 34]          36,928\n",
      "     BatchNorm2d-283           [-1, 64, 74, 34]             128\n",
      "            ReLU-284           [-1, 64, 74, 34]               0\n",
      "            Conv-285           [-1, 64, 74, 34]               0\n",
      "        Upsample-286           [-1, 64, 74, 34]               0\n",
      " ConvTranspose2d-287          [-1, 32, 146, 66]           8,224\n",
      "     BatchNorm2d-288          [-1, 32, 146, 66]              64\n",
      "            ReLU-289          [-1, 32, 146, 66]               0\n",
      "          DeConv-290          [-1, 32, 146, 66]               0\n",
      "          Conv2d-291          [-1, 32, 146, 66]          18,464\n",
      "     BatchNorm2d-292          [-1, 32, 146, 66]              64\n",
      "            ReLU-293          [-1, 32, 146, 66]               0\n",
      "            Conv-294          [-1, 32, 146, 66]               0\n",
      "          Conv2d-295          [-1, 32, 146, 66]           9,248\n",
      "     BatchNorm2d-296          [-1, 32, 146, 66]              64\n",
      "            ReLU-297          [-1, 32, 146, 66]               0\n",
      "            Conv-298          [-1, 32, 146, 66]               0\n",
      "        Upsample-299          [-1, 32, 146, 66]               0\n",
      "          Conv2d-300          [-1, 17, 146, 66]           4,913\n",
      "     BatchNorm2d-301          [-1, 17, 146, 66]              34\n",
      "            ReLU-302          [-1, 17, 146, 66]               0\n",
      "            Conv-303          [-1, 17, 146, 66]               0\n",
      "            Unet-304          [-1, 17, 146, 66]               0\n",
      "          Conv2d-305          [-1, 32, 134, 58]           5,792\n",
      "     BatchNorm2d-306          [-1, 32, 134, 58]              64\n",
      "            ReLU-307          [-1, 32, 134, 58]               0\n",
      "            Conv-308          [-1, 32, 134, 58]               0\n",
      "          Conv2d-309          [-1, 32, 134, 58]           9,248\n",
      "     BatchNorm2d-310          [-1, 32, 134, 58]              64\n",
      "            ReLU-311          [-1, 32, 134, 58]               0\n",
      "            Conv-312          [-1, 32, 134, 58]               0\n",
      "          Conv2d-313          [-1, 32, 134, 58]           9,248\n",
      "     BatchNorm2d-314          [-1, 32, 134, 58]              64\n",
      "            ReLU-315          [-1, 32, 134, 58]               0\n",
      "            Conv-316          [-1, 32, 134, 58]               0\n",
      "          Conv2d-317           [-1, 64, 68, 30]          18,496\n",
      "     BatchNorm2d-318           [-1, 64, 68, 30]             128\n",
      "            ReLU-319           [-1, 64, 68, 30]               0\n",
      "            Conv-320           [-1, 64, 68, 30]               0\n",
      "      Downsample-321           [-1, 64, 68, 30]               0\n",
      "          Conv2d-322           [-1, 64, 68, 30]          36,928\n",
      "     BatchNorm2d-323           [-1, 64, 68, 30]             128\n",
      "            ReLU-324           [-1, 64, 68, 30]               0\n",
      "            Conv-325           [-1, 64, 68, 30]               0\n",
      "          Conv2d-326           [-1, 64, 68, 30]          36,928\n",
      "     BatchNorm2d-327           [-1, 64, 68, 30]             128\n",
      "            ReLU-328           [-1, 64, 68, 30]               0\n",
      "            Conv-329           [-1, 64, 68, 30]               0\n",
      "          Conv2d-330          [-1, 128, 35, 16]          73,856\n",
      "     BatchNorm2d-331          [-1, 128, 35, 16]             256\n",
      "            ReLU-332          [-1, 128, 35, 16]               0\n",
      "            Conv-333          [-1, 128, 35, 16]               0\n",
      "      Downsample-334          [-1, 128, 35, 16]               0\n",
      "          Conv2d-335          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-336          [-1, 128, 35, 16]             256\n",
      "            ReLU-337          [-1, 128, 35, 16]               0\n",
      "            Conv-338          [-1, 128, 35, 16]               0\n",
      "          Conv2d-339          [-1, 128, 35, 16]         147,584\n",
      "     BatchNorm2d-340          [-1, 128, 35, 16]             256\n",
      "            ReLU-341          [-1, 128, 35, 16]               0\n",
      "            Conv-342          [-1, 128, 35, 16]               0\n",
      "          Conv2d-343           [-1, 256, 19, 9]         295,168\n",
      "     BatchNorm2d-344           [-1, 256, 19, 9]             512\n",
      "            ReLU-345           [-1, 256, 19, 9]               0\n",
      "            Conv-346           [-1, 256, 19, 9]               0\n",
      "      Downsample-347           [-1, 256, 19, 9]               0\n",
      "          Conv2d-348           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-349           [-1, 256, 19, 9]             512\n",
      "            ReLU-350           [-1, 256, 19, 9]               0\n",
      "            Conv-351           [-1, 256, 19, 9]               0\n",
      "          Conv2d-352           [-1, 256, 19, 9]         590,080\n",
      "     BatchNorm2d-353           [-1, 256, 19, 9]             512\n",
      "            ReLU-354           [-1, 256, 19, 9]               0\n",
      "            Conv-355           [-1, 256, 19, 9]               0\n",
      "          Conv2d-356           [-1, 512, 11, 6]       1,180,160\n",
      "     BatchNorm2d-357           [-1, 512, 11, 6]           1,024\n",
      "            ReLU-358           [-1, 512, 11, 6]               0\n",
      "            Conv-359           [-1, 512, 11, 6]               0\n",
      "      Downsample-360           [-1, 512, 11, 6]               0\n",
      " ConvTranspose2d-361          [-1, 256, 20, 10]         524,544\n",
      "     BatchNorm2d-362          [-1, 256, 20, 10]             512\n",
      "            ReLU-363          [-1, 256, 20, 10]               0\n",
      "          DeConv-364          [-1, 256, 20, 10]               0\n",
      "          Conv2d-365          [-1, 256, 20, 10]       1,179,904\n",
      "     BatchNorm2d-366          [-1, 256, 20, 10]             512\n",
      "            ReLU-367          [-1, 256, 20, 10]               0\n",
      "            Conv-368          [-1, 256, 20, 10]               0\n",
      "          Conv2d-369          [-1, 256, 20, 10]         590,080\n",
      "     BatchNorm2d-370          [-1, 256, 20, 10]             512\n",
      "            ReLU-371          [-1, 256, 20, 10]               0\n",
      "            Conv-372          [-1, 256, 20, 10]               0\n",
      "        Upsample-373          [-1, 256, 20, 10]               0\n",
      " ConvTranspose2d-374          [-1, 128, 38, 18]         131,200\n",
      "     BatchNorm2d-375          [-1, 128, 38, 18]             256\n",
      "            ReLU-376          [-1, 128, 38, 18]               0\n",
      "          DeConv-377          [-1, 128, 38, 18]               0\n",
      "          Conv2d-378          [-1, 128, 38, 18]         295,040\n",
      "     BatchNorm2d-379          [-1, 128, 38, 18]             256\n",
      "            ReLU-380          [-1, 128, 38, 18]               0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Conv-381          [-1, 128, 38, 18]               0\n",
      "          Conv2d-382          [-1, 128, 38, 18]         147,584\n",
      "     BatchNorm2d-383          [-1, 128, 38, 18]             256\n",
      "            ReLU-384          [-1, 128, 38, 18]               0\n",
      "            Conv-385          [-1, 128, 38, 18]               0\n",
      "        Upsample-386          [-1, 128, 38, 18]               0\n",
      " ConvTranspose2d-387           [-1, 64, 74, 34]          32,832\n",
      "     BatchNorm2d-388           [-1, 64, 74, 34]             128\n",
      "            ReLU-389           [-1, 64, 74, 34]               0\n",
      "          DeConv-390           [-1, 64, 74, 34]               0\n",
      "          Conv2d-391           [-1, 64, 74, 34]          73,792\n",
      "     BatchNorm2d-392           [-1, 64, 74, 34]             128\n",
      "            ReLU-393           [-1, 64, 74, 34]               0\n",
      "            Conv-394           [-1, 64, 74, 34]               0\n",
      "          Conv2d-395           [-1, 64, 74, 34]          36,928\n",
      "     BatchNorm2d-396           [-1, 64, 74, 34]             128\n",
      "            ReLU-397           [-1, 64, 74, 34]               0\n",
      "            Conv-398           [-1, 64, 74, 34]               0\n",
      "        Upsample-399           [-1, 64, 74, 34]               0\n",
      " ConvTranspose2d-400          [-1, 32, 146, 66]           8,224\n",
      "     BatchNorm2d-401          [-1, 32, 146, 66]              64\n",
      "            ReLU-402          [-1, 32, 146, 66]               0\n",
      "          DeConv-403          [-1, 32, 146, 66]               0\n",
      "          Conv2d-404          [-1, 32, 146, 66]          18,464\n",
      "     BatchNorm2d-405          [-1, 32, 146, 66]              64\n",
      "            ReLU-406          [-1, 32, 146, 66]               0\n",
      "            Conv-407          [-1, 32, 146, 66]               0\n",
      "          Conv2d-408          [-1, 32, 146, 66]           9,248\n",
      "     BatchNorm2d-409          [-1, 32, 146, 66]              64\n",
      "            ReLU-410          [-1, 32, 146, 66]               0\n",
      "            Conv-411          [-1, 32, 146, 66]               0\n",
      "        Upsample-412          [-1, 32, 146, 66]               0\n",
      "          Conv2d-413          [-1, 17, 146, 66]           4,913\n",
      "     BatchNorm2d-414          [-1, 17, 146, 66]              34\n",
      "            ReLU-415          [-1, 17, 146, 66]               0\n",
      "            Conv-416          [-1, 17, 146, 66]               0\n",
      "            Unet-417          [-1, 17, 146, 66]               0\n",
      "================================================================\n",
      "Total params: 25,620,444\n",
      "Trainable params: 25,620,444\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.36\n",
      "Forward/backward pass size (MB): 459.64\n",
      "Params size (MB): 97.73\n",
      "Estimated Total Size (MB): 557.73\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    complete_model = VRUNet().cuda()\n",
    "\n",
    "    summary(complete_model, (3, 269, 117))\n",
    "\n",
    "    # model = Unet(torch.randn(2, 17, 269, 117).cuda()).cuda()\n",
    "\n",
    "    # model = BackBone().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
